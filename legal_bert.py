# -*- coding: utf-8 -*-
"""Legal_BERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ItjHRg_Ma1rh9xYnJBso9w9LVmc-IK5j
"""

!pip install -q transformers datasets torch scikit-learn pandas numpy

import re
import numpy as np
import pandas as pd
import torch

from datasets import load_dataset, Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer
)

from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics import f1_score, precision_score, recall_score

dataset = load_dataset(
    "json",
    data_files="CUAD_v1.json",
    field="data"
)

dataset

samples = []

for contract in dataset["train"]:
    for para in contract["paragraphs"]:
        context = para["context"]

        for qa in para["qas"]:
            question = qa["question"]

            for ans in qa["answers"]:
                text = ans["text"].strip()
                if text:
                    samples.append({
                        "text": text,
                        "question": question
                    })

df = pd.DataFrame(samples)
df.head()

def extract_clause(question):
    match = re.search(r'"([^"]+)"', question)
    return match.group(1) if match else None

df["clause_type"] = df["question"].apply(extract_clause)

CLAUSE_TYPES = ["Document Name", "Parties", "Agreement Date"
"Effective Date", "Expiration Date", "Renewal Term", "Notice Period to Terminate Renewal",
"Governing Law", "Most Favored Nation", "Non-Compete", "Exclusivity", "No-Solicit of Customers",
"Competitive Restriction Exception", "No-Solicit of Employees","Non-Disparagement", "Termination for Convenience",
"Rofr/Rofo/Rofn", "Change of Control", "Anti-Assignment", "Revenue/Profit Sharing", "Price Restrictions",
"Minimum Commitment", "Volume Restriction", "IP Ownership Assignment", "Joint IP Ownership", "License Grant"
,"Non-Transferable License", "Affiliate License-Licensor", "Affiliate License-Licensee"
,"Unlimited/All-You-Can-Eat-License", "Irrevocable or Perpetual License", "Source Code Escrow", "Post-Termination Services"
,"Audit Rights", "Uncapped Liability", "Cap on Liability", "Liquidated Damages", "Warranty Duration"
,"Insurance", "Covenant Not to Sue", "Third Party Beneficiary"]

print(df["clause_type"].tolist())

df.shape

df = df[df["clause_type"].isin(CLAUSE_TYPES)]
df.shape

df["labels"] = df["clause_type"].apply(lambda x: [x])

print(df["labels"].tolist())

mlb = MultiLabelBinarizer(classes=CLAUSE_TYPES)
y = mlb.fit_transform(df["labels"])

print(y.shape)  # (num_samples, 41)

(y.sum(axis=1) > 0).mean()

hf_dataset = Dataset.from_dict({
    "text": df["text"].tolist(),
    "labels": y.astype(float).tolist()
})

hf_dataset

tokenizer = AutoTokenizer.from_pretrained(
    "nlpaueb/legal-bert-base-uncased"
)

def tokenize(batch):
    return tokenizer(
        batch["text"],
        padding="max_length",
        truncation=True,
        max_length=512
    )

hf_dataset = hf_dataset.map(tokenize, batched=True)
hf_dataset = hf_dataset.remove_columns(["text"])
hf_dataset = hf_dataset.map(
    lambda x: {"labels": torch.tensor(x["labels"], dtype=torch.float)}
)

hf_dataset.set_format(type="torch")

dataset_split = hf_dataset.train_test_split(test_size=0.1)
train_ds = dataset_split["train"]
val_ds = dataset_split["test"]

model = AutoModelForSequenceClassification.from_pretrained(
    "nlpaueb/legal-bert-base-uncased",
    num_labels=len(CLAUSE_TYPES),
    problem_type="multi_label_classification"
)

training_args = TrainingArguments(
    output_dir="./legal-bert-cuad",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=5,
    weight_decay=0.01,
    logging_steps=100,
    load_best_model_at_end=True
)

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    probs = torch.sigmoid(torch.tensor(logits))
    preds = (probs > 0.5).int().numpy()

    return {
        "micro_f1": f1_score(labels, preds, average="micro"),
        "macro_f1": f1_score(labels, preds, average="macro"),
        "precision": precision_score(labels, preds, average="micro"),
        "recall": recall_score(labels, preds, average="micro")
    }

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer.train()

text = "This agreement shall be governed by the laws of India."

inputs = tokenizer(text, return_tensors="pt", truncation=True)
outputs = model(**inputs.to(model.device))

preds = (torch.sigmoid(outputs.logits) > 0.5).squeeze()

predicted_clauses = [
    CLAUSE_TYPES[i] for i, val in enumerate(preds) if val
]

predicted_clauses

SAVE_DIR = "/content/legal-bert-cuad-finetuned"

trainer.save_model(SAVE_DIR)
tokenizer.save_pretrained(SAVE_DIR)

SAVE_DIR = "/content/drive/MyDrive/models/legal-bert-cuad-finetuned"

import os
os.makedirs(SAVE_DIR, exist_ok=True)

trainer.save_model(SAVE_DIR)
tokenizer.save_pretrained(SAVE_DIR)

import joblib
joblib.dump(mlb, f"{SAVE_DIR}/label_binarizer.pkl")

import json

SAVE_DIR = "/content/drive/MyDrive/models/legal-bert-cuad-finetuned"

tokenizer = AutoTokenizer.from_pretrained(SAVE_DIR)
model = AutoModelForSequenceClassification.from_pretrained(SAVE_DIR)
model.eval()

id2label = model.config.id2label

def predict(text):
  inputs = tokenizer(
      text,
      return_tensors="pt",
      truncation=True,
      max_length=256
  )

  with torch.no_grad():
    outputs = model(**inputs)

  probs = torch.softmax(outputs.logits, dim = 1)
  confidence, pred = torch.max(probs, dim = 1)

  return id2label[pred.item()], round(confidence.item(), 3)

with open("/content/manual-cluases.json") as f:
    clauses = json.load(f)

results = []

for c in clauses:
    predicted, confidence = predict(c["text"])
    label_idx = int(predicted.replace("LABEL_", ""))
    predicted = CLAUSE_TYPES[label_idx]
    results.append({
        "text": c["text"],
        "expected": c["expected_label"],
        "predicted": predicted,
        "confidence": confidence,
        "correct": predicted == c["expected_label"]
    })

count = 0
for r in results:
    print("-" * 80)
    print(f"Clause: {r['text']}")
    print(f"Expected : {r['expected']}")
    print(f"Predicted: {r['predicted']} (confidence={r['confidence']})")
    print(f"Correct  : {r['correct']}")
    if r["correct"]:
        count += 1

print(f"Accuracy: {count / len(results)}")

